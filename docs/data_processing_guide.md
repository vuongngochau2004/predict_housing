# ğŸ“Š HÆ°á»›ng Dáº«n Xá»­ LÃ½ Dá»¯ Liá»‡u Báº¥t Äá»™ng Sáº£n

## ğŸ“‹ Tá»•ng Quan Pipeline

```
Raw Data (nhatot_crawl4ai.csv - 23,527 rows)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1-2: CLEAN & DEDUPE                                    â”‚
â”‚ â†’ 7,150 rows â†’ 6,396 rows                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: PARSE PRICE                                         â”‚
â”‚ â†’ "3,5 tá»·" â†’ 3.5 (tá»· VNÄ)                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: OUTLIER REMOVAL                                     â”‚
â”‚ â†’ Domain bounds + IQR (k=3.0)                               â”‚
â”‚ â†’ 5,967 rows                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: HANDLE MISSING VALUES                               â”‚
â”‚ â†’ TÃ­nh toÃ¡n tá»« features liÃªn quan                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 6: FEATURE ENGINEERING                                 â”‚
â”‚ â†’ 4 features má»›i                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 7: ENCODING                                            â”‚
â”‚ â†’ OOF Target Encoding + One-Hot + Ordinal                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Final Data (5,967 rows Ã— 20 features)
```

---

## ğŸ“ Chi Tiáº¿t Tá»«ng BÆ°á»›c

### Step 1-2: Clean & Dedupe

**WHY?**
- Raw data tá»« crawl cÃ³ nhiá»u rows trá»‘ng, trÃ¹ng láº·p
- Rows cÃ³ quÃ¡ nhiá»u NaN khÃ´ng mang nhiá»u thÃ´ng tin

**HOW?**
```python
# Bá» rows hoÃ n toÃ n trá»‘ng
df_cleaned = df.dropna(how='all')

# Bá» rows cÃ³ > 6 giÃ¡ trá»‹ NaN
missing_count = df_cleaned.isnull().sum(axis=1)
df_cleaned = df_cleaned[missing_count <= 6]

# XoÃ¡ duplicates
df = df.drop_duplicates(keep="first")
```

**Káº¾T QUáº¢:** 23,527 â†’ 7,150 â†’ 6,396 rows

---

### Step 3: Parse Price

**WHY?**
- GiÃ¡ dáº¡ng text ("3,5 tá»·", "750 triá»‡u") khÃ´ng thá»ƒ tÃ­nh toÃ¡n
- Cáº§n chuyá»ƒn vá» Ä‘Æ¡n vá»‹ thá»‘ng nháº¥t (tá»· VNÄ)

**HOW?**
```python
def convert_price_to_billion(price_str):
    if 'tá»·' in price_str:
        return float(value)       # "3,5 tá»·" â†’ 3.5
    elif 'triá»‡u' in price_str:
        return float(value) / 1000  # "750 triá»‡u" â†’ 0.75
```

**Káº¾T QUáº¢:** 
- Min: 0.00 tá»·
- Max: 1,250 tá»· (outlier!)
- Median: 5.90 tá»·

---

### Step 4: Outlier Removal

**WHY?**
- Outliers cá»±c Ä‘oan áº£nh hÆ°á»Ÿng training
- Cáº§n giá»¯ láº¡i outliers "tháº­t" (biá»‡t thá»±, nhÃ  máº·t phá»‘ Ä‘áº¯c Ä‘á»‹a)

**HOW?**

**1. Domain Knowledge Bounds:**
```python
PRICE_MIN = 0.2      # tá»· - dÆ°á»›i 200 triá»‡u khÃ´ng há»£p lÃ½
PRICE_MAX = 200      # tá»· - trÃªn 200 tá»· ráº¥t hiáº¿m

AREA_MIN = 10        # m2
AREA_MAX = 1500      # m2

WIDTH_MIN = 2, WIDTH_MAX = 50   # m
LENGTH_MIN = 3, LENGTH_MAX = 100  # m
ROOM_MAX = 20
FLOOR_MAX = 15
```

**2. IQR Filter (k=3.0 - nháº¹ tay):**
```python
def iqr_filter(data, col, k=3.0):
    q1 = data[col].quantile(0.25)
    q3 = data[col].quantile(0.75)
    iqr = q3 - q1
    return data[data[col].between(q1 - k*iqr, q3 + k*iqr)]
```

> **Táº¡i sao k=3.0?** 
> - k=1.5 quÃ¡ cháº·t, loáº¡i nhiá»u outliers tháº­t (nhÃ  cao cáº¥p)
> - k=3.0 giá»¯ láº¡i 99.7% data trong phÃ¢n phá»‘i chuáº©n

**Káº¾T QUáº¢:** 6,396 â†’ 5,967 rows

---

### Step 5: Handle Missing Values

**WHY?**
- Models khÃ´ng xá»­ lÃ½ NaN trá»±c tiáº¿p
- Cáº§n cÃ¡ch Ä‘iá»n há»£p lÃ½ dá»±a trÃªn domain knowledge

**HOW?**

| Cá»™t | % NaN | PhÆ°Æ¡ng phÃ¡p | LÃ½ do |
|-----|-------|-------------|-------|
| Chiá»u ngang/dÃ i | ~20% | TÃ­nh tá»« Diá»‡n tÃ­ch | DT = Ngang Ã— DÃ i |
| Sá»‘ phÃ²ng ngá»§ | 1.2% | TÃ­nh tá»« Diá»‡n tÃ­ch | Median mÂ²/phÃ²ng |
| Sá»‘ phÃ²ng vá»‡ sinh | 26% | TÃ­nh tá»« Sá»‘ phÃ²ng ngá»§ | Group median |
| Sá»‘ táº§ng | 34% | Median | Global median |
| HÆ°á»›ng | 75% | "KhÃ´ng xÃ¡c Ä‘á»‹nh" | Category má»›i |
| Ná»™i tháº¥t | 48% | "KhÃ´ng xÃ¡c Ä‘á»‹nh" | Category má»›i |

```python
# Chiá»u ngang tá»« DT vÃ  Chiá»u dÃ i
df.loc[m, 'Chiá»u ngang (m)'] = df['Diá»‡n tÃ­ch (m2)'] / df['Chiá»u dÃ i (m)']

# WC tá»« PhÃ²ng ngá»§ (group median)
wc_med = df.groupby('Sá»‘ phÃ²ng ngá»§')['Sá»‘ phÃ²ng vá»‡ sinh'].median()
df['Sá»‘ phÃ²ng vá»‡ sinh'] = df['Sá»‘ phÃ²ng ngá»§'].map(wc_med)
```

> **Táº¡i sao HÆ°á»›ng/Ná»™i tháº¥t â†’ "KhÃ´ng xÃ¡c Ä‘á»‹nh"?**
> - NaN ráº¥t cao (~50-75%)
> - ÄÃ¢y lÃ  thÃ´ng tin seller KHÃ”NG CUNG Cáº¤P, khÃ´ng pháº£i "khÃ´ng biáº¿t"
> - Model cÃ³ thá»ƒ há»c pattern "khÃ´ng cung cáº¥p" riÃªng

---

### Step 6: Feature Engineering

**WHY?**
- Features thÃ´ chá»‰ capture 1 khÃ­a cáº¡nh
- Features má»›i capture relationships giá»¯a cÃ¡c features

**HOW?**

| Feature Má»›i | CÃ´ng Thá»©c | Insight |
|-------------|-----------|---------|
| **GiÃ¡_per_m2** | GiÃ¡ / Diá»‡n tÃ­ch | Indicator cá»§a khu vá»±c Ä‘áº¯t/ráº» |
| **Tá»•ng_phÃ²ng** | Sá»‘ phÃ²ng ngá»§ + WC | Tá»•ng tiá»‡n nghi |
| **Aspect_ratio** | Ngang / DÃ i | HÃ¬nh dáº¡ng lÃ´ (vuÃ´ng vs dÃ i) |
| **Diá»‡n_tÃ­ch_per_phÃ²ng** | DT / Tá»•ng phÃ²ng | Rá»™ng rÃ£i hay cháº­t chá»™i |

> **Táº¡i sao GiÃ¡_per_m2 quan trá»ng?**
> - LÃ  proxy cho "giÃ¡ trá»‹ vá»‹ trÃ­"
> - Correlation cao vá»›i target trÆ°á»›c khi encode location

---

### Step 7: Encoding

**WHY?**
- Models cáº§n input sá»‘
- High-cardinality features (PhÆ°á»ng/XÃ£) gÃ¢y curse of dimensionality náº¿u One-Hot

**HOW?**

#### 1. OOF Target Encoding: ThÃ nh phá»‘

```python
# 5-Fold: encode má»—i row báº±ng data tá»« 4 folds cÃ²n láº¡i
kf = KFold(n_splits=5, shuffle=True, random_state=42)

for train_idx, val_idx in kf.split(df):
    fold_train = df.iloc[train_idx]
    fold_val = df.iloc[val_idx]
    
    # Mean tá»« TRAIN fold
    means = fold_train.groupby('ThÃ nh phá»‘')[target].mean()
    counts = fold_train.groupby('ThÃ nh phá»‘')[target].count()
    
    # Smoothing: trÃ¡nh overfitting category Ã­t samples
    smooth = (means*counts + global_mean*10) / (counts + 10)
    
    # Apply cho VAL fold
    df.loc[val_idx, 'ThÃ nh phá»‘_encoded'] = fold_val['ThÃ nh phá»‘'].map(smooth)
```

> **Táº¡i sao dÃ¹ng K-Fold?**
> - TrÃ¡nh data leakage
> - Má»—i row Ä‘Æ°á»£c encode báº±ng data KHÃ”NG CHá»¨A giÃ¡ trá»‹ cá»§a chÃ­nh nÃ³

> **Táº¡i sao Smoothing?**
> - PhÆ°á»ng chá»‰ cÃ³ 3 nhÃ  â†’ mean khÃ´ng Ä‘Ã¡ng tin
> - Smoothing kÃ©o vá» global mean Ä‘á»ƒ trÃ¡nh overfitting

#### 2. Target Encoding: PhÆ°á»ng/XÃ£

```python
# Simple smoothed (khÃ´ng K-Fold vÃ¬ Ä‘Ã£ cÃ³ K-Fold cho ThÃ nh phá»‘)
smooth = (counts*means + global_mean*10) / (counts + 10)
df['PhÆ°á»ng/XÃ£_encoded'] = df['PhÆ°á»ng/XÃ£'].map(smooth)
```

#### 3. One-Hot Encoding: Loáº¡i hÃ¬nh

```python
# Low cardinality (4 categories) â†’ One-Hot OK
df = pd.concat([df, pd.get_dummies(df['Loáº¡i hÃ¬nh'], prefix='Loáº¡i hÃ¬nh')], axis=1)
```

#### 4. Ordinal Encoding: Giáº¥y tá» phÃ¡p lÃ½

```python
# CÃ³ thá»© tá»± tá»± nhiÃªn
phap_ly_order = {
    'ÄÃ£ cÃ³ sá»•': 4,          # Tá»‘t nháº¥t
    'Sá»• chung': 3,
    'Äang chá» sá»•': 2,
    'Giáº¥y tá» viáº¿t tay': 1,
    'KhÃ´ng cÃ³ sá»•': 0         # Rá»§i ro nháº¥t
}
```

---

## ğŸ“Š Output Files

| File | MÃ´ táº£ |
|------|-------|
| `cleaned_nhatot_data.csv` | Sau bÆ°á»›c 1-4 |
| `data_nan_handled_final.csv` | Sau bÆ°á»›c 5 |
| `data_with_new_features.csv` | Sau bÆ°á»›c 6 |
| `data_encoded.csv` | Sau bÆ°á»›c 7 (final) |

---

## ğŸ“ Key Takeaways

1. **Domain Knowledge quan trá»ng hÆ¡n ká»¹ thuáº­t**
   - Bounds tá»« thá»±c táº¿ BÄS hiá»‡u quáº£ hÆ¡n IQR blind

2. **K-Fold Target Encoding**
   - LuÃ´n dÃ¹ng khi encode based on target
   - Smoothing giÃºp trÃ¡nh overfitting

3. **Missing Values khÃ¡c nhau cÃ³ strategy khÃ¡c nhau**
   - Numeric â†’ tÃ­nh tá»« features liÃªn quan
   - Categorical vá»›i NaN cao â†’ category riÃªng

4. **Feature Engineering tá»« domain**
   - GiÃ¡/mÂ² lÃ  indicator quan trá»ng nháº¥t cho location value
