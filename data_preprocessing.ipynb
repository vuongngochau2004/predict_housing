{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ti·ªÅn X·ª≠ L√Ω D·ªØ Li·ªáu B·∫•t ƒê·ªông S·∫£n Nhatot\n",
    "## Data Preprocessing for Nhatot Housing Dataset\n",
    "\n",
    "Notebook n√†y th·ª±c hi·ªán c√°c b∆∞·ªõc:\n",
    "1. üìÇ Load d·ªØ li·ªáu\n",
    "2. üßπ L√†m s·∫°ch d·ªØ li·ªáu\n",
    "3. üîç Ph√¢n t√≠ch missing values\n",
    "4. üîß X·ª≠ l√Ω missing values\n",
    "5. üè∑Ô∏è Encoding categorical features\n",
    "6. ‚öôÔ∏è Feature engineering\n",
    "7. üìè Scaling features (optional)\n",
    "8. üíæ L∆∞u d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω\n",
    "\n",
    "**L∆∞u √Ω:** File g·ªëc `nhatot_crawl4ai.csv` s·∫Ω KH√îNG b·ªã thay ƒë·ªïi!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# C·∫•u h√¨nh hi·ªÉn th·ªã\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"‚úì Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load D·ªØ Li·ªáu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load d·ªØ li·ªáu\n",
    "file_path = 'nhatot_crawl4ai.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# T·∫°o b·∫£n sao ƒë·ªÉ b·∫£o to√†n d·ªØ li·ªáu g·ªëc\n",
    "df_original = df.copy()\n",
    "\n",
    "print(f\"üìÇ Loaded data:\")\n",
    "print(f\"   Rows: {len(df):,}\")\n",
    "print(f\"   Columns: {len(df.columns)}\")\n",
    "print(f\"   ‚úì Created backup of original data\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem 5 d√≤ng ƒë·∫ßu ti√™n\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Th√¥ng tin t·ªïng quan\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. L√†m S·∫°ch D·ªØ Li·ªáu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. X√≥a C√°c D√≤ng Tr·ªëng Ho√†n To√†n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üßπ Cleaning empty rows...\")\n",
    "initial_count = len(df)\n",
    "\n",
    "# X√≥a d√≤ng c√≥ t·∫•t c·∫£ gi√° tr·ªã l√† NaN\n",
    "df = df.dropna(how='all')\n",
    "\n",
    "removed = initial_count - len(df)\n",
    "print(f\"‚úì Removed {removed:,} empty rows\")\n",
    "print(f\"  Remaining: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. X√≥a D·ªØ Li·ªáu Tr√πng L·∫∑p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Removing duplicates...\")\n",
    "initial_count = len(df)\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "removed = initial_count - len(df)\n",
    "print(f\"‚úì Removed {removed:,} duplicate rows\")\n",
    "print(f\"  Remaining: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ph√¢n T√≠ch Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ph√¢n t√≠ch missing values\n",
    "missing_stats = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "\n",
    "missing_stats = missing_stats[missing_stats['Missing_Count'] > 0].sort_values(\n",
    "    'Missing_Percentage', ascending=False\n",
    ")\n",
    "\n",
    "print(\"üìä Missing Values Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "print(missing_stats.to_string(index=False))\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "plt.figure(figsize=(12, 6))\n",
    "if len(missing_stats) > 0:\n",
    "    sns.barplot(data=missing_stats, x='Column', y='Missing_Percentage', palette='viridis')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.title('Missing Values by Column (%)', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Missing Percentage (%)')\n",
    "    plt.xlabel('Column Name')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. X·ª≠ L√Ω C·ªôt Gi√° (Price Column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_price(price_str):\n",
    "    \"\"\"\n",
    "    Convert Vietnamese price format to numeric value\n",
    "    \n",
    "    Examples:\n",
    "        \"1,5 t·ª∑\" -> 1500000000\n",
    "        \"500 tri·ªáu\" -> 500000000\n",
    "    \"\"\"\n",
    "    if pd.isna(price_str):\n",
    "        return np.nan\n",
    "    \n",
    "    price_str = str(price_str).strip().replace('\"', '')\n",
    "    \n",
    "    try:\n",
    "        if 't·ª∑' in price_str:\n",
    "            value = price_str.replace('t·ª∑', '').strip().replace(',', '.')\n",
    "            return float(value) * 1_000_000_000\n",
    "        elif 'tri·ªáu' in price_str:\n",
    "            value = price_str.replace('tri·ªáu', '').strip().replace(',', '.')\n",
    "            return float(value) * 1_000_000\n",
    "        else:\n",
    "            value = price_str.replace(',', '.')\n",
    "            return float(value)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# √Åp d·ª•ng conversion\n",
    "print(\"üí∞ Processing price column...\")\n",
    "df['Gi√° b√°n (VND)'] = df['Gi√° b√°n'].apply(parse_price)\n",
    "\n",
    "# X√≥a c√°c d√≤ng c√≥ gi√° kh√¥ng h·ª£p l·ªá\n",
    "initial_count = len(df)\n",
    "df = df.dropna(subset=['Gi√° b√°n (VND)'])\n",
    "removed = initial_count - len(df)\n",
    "\n",
    "print(f\"‚úì Converted prices to numeric\")\n",
    "print(f\"  Removed {removed:,} rows with invalid prices\")\n",
    "print(f\"  Price range: {df['Gi√° b√°n (VND)'].min():,.0f} - {df['Gi√° b√°n (VND)'].max():,.0f} VND\")\n",
    "print(f\"  Mean price: {df['Gi√° b√°n (VND)'].mean():,.0f} VND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize price distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df['Gi√° b√°n (VND)'] / 1e9, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Gi√° (t·ª∑ VND)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Price Distribution')\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df['Gi√° b√°n (VND)'] / 1e9)\n",
    "axes[1].set_ylabel('Gi√° (t·ª∑ VND)')\n",
    "axes[1].set_title('Price Box Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. X·ª≠ L√Ω C√°c C·ªôt S·ªë (Numeric Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_numeric_column(val):\n",
    "    \"\"\"Parse numeric columns that might have special values\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    \n",
    "    val_str = str(val).strip().lower()\n",
    "    \n",
    "    # Handle special values like \"nhi·ªÅu h∆°n 6\"\n",
    "    if 'nhi·ªÅu h∆°n' in val_str or 'h∆°n' in val_str:\n",
    "        import re\n",
    "        numbers = re.findall(r'\\d+', val_str)\n",
    "        if numbers:\n",
    "            return float(numbers[0]) + 1\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        return float(val_str.replace(',', '.'))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# √Åp d·ª•ng cho c√°c c·ªôt s·ªë\n",
    "print(\"üî¢ Processing numeric columns...\")\n",
    "numeric_cols = [\n",
    "    'Di·ªán t√≠ch (m2)',\n",
    "    'Chi·ªÅu ngang (m)',\n",
    "    'Chi·ªÅu d√†i (m)',\n",
    "    'S·ªë ph√≤ng ng·ªß',\n",
    "    'S·ªë ph√≤ng v·ªá sinh',\n",
    "    'S·ªë t·∫ßng'\n",
    "]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(parse_numeric_column)\n",
    "        print(f\"  ‚úì Cleaned {col}\")\n",
    "\n",
    "print(\"‚úì All numeric columns processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. X·ª≠ L√Ω Missing Values\n",
    "\n",
    "### Chi·∫øn l∆∞·ª£c:\n",
    "- **Numeric columns**: ƒêi·ªÅn b·∫±ng median\n",
    "- **Categorical columns**: ƒêi·ªÅn b·∫±ng mode ho·∫∑c \"Kh√¥ng r√µ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß Handling missing values...\")\n",
    "\n",
    "# 1. Numeric columns: fill with median\n",
    "numeric_cols_in_df = df.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols_in_df:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        median_val = df[col].median()\n",
    "        df[col].fillna(median_val, inplace=True)\n",
    "        print(f\"  ‚úì Filled {col} with median: {median_val:.2f}\")\n",
    "\n",
    "# 2. Categorical columns: fill with mode or 'Kh√¥ng r√µ'\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if col == 'Gi√° b√°n':  # Skip original price column\n",
    "        continue\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        mode_val = df[col].mode()\n",
    "        if len(mode_val) > 0:\n",
    "            df[col].fillna(mode_val[0], inplace=True)\n",
    "            print(f\"  ‚úì Filled {col} with mode: {mode_val[0]}\")\n",
    "        else:\n",
    "            df[col].fillna('Kh√¥ng r√µ', inplace=True)\n",
    "            print(f\"  ‚úì Filled {col} with 'Kh√¥ng r√µ'\")\n",
    "\n",
    "print(f\"\\n‚úì Missing values handled. Remaining rows: {len(df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ki·ªÉm tra l·∫°i missing values\n",
    "remaining_missing = df.isnull().sum().sum()\n",
    "print(f\"Remaining missing values: {remaining_missing}\")\n",
    "\n",
    "if remaining_missing > 0:\n",
    "    print(\"\\nColumns still have missing values:\")\n",
    "    print(df.isnull().sum()[df.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Engineering\n",
    "\n",
    "T·∫°o c√°c features m·ªõi t·ª´ d·ªØ li·ªáu hi·ªán c√≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚öôÔ∏è  Feature Engineering...\")\n",
    "\n",
    "# 1. Price per square meter\n",
    "if 'Di·ªán t√≠ch (m2)' in df.columns and 'Gi√° b√°n (VND)' in df.columns:\n",
    "    df['Gi√°/m2'] = df['Gi√° b√°n (VND)'] / df['Di·ªán t√≠ch (m2)']\n",
    "    print(\"  ‚úì Created 'Gi√°/m2' (price per sqm)\")\n",
    "\n",
    "# 2. Total rooms\n",
    "if 'S·ªë ph√≤ng ng·ªß' in df.columns and 'S·ªë ph√≤ng v·ªá sinh' in df.columns:\n",
    "    df['T·ªïng s·ªë ph√≤ng'] = df['S·ªë ph√≤ng ng·ªß'] + df['S·ªë ph√≤ng v·ªá sinh']\n",
    "    print(\"  ‚úì Created 'T·ªïng s·ªë ph√≤ng' (total rooms)\")\n",
    "\n",
    "# 3. Area from dimensions\n",
    "if 'Chi·ªÅu ngang (m)' in df.columns and 'Chi·ªÅu d√†i (m)' in df.columns:\n",
    "    df['Di·ªán t√≠ch ∆∞·ªõc t√≠nh'] = df['Chi·ªÅu ngang (m)'] * df['Chi·ªÅu d√†i (m)']\n",
    "    print(\"  ‚úì Created 'Di·ªán t√≠ch ∆∞·ªõc t√≠nh' (estimated area)\")\n",
    "\n",
    "# 4. Property size category\n",
    "if 'Di·ªán t√≠ch (m2)' in df.columns:\n",
    "    def categorize_size(area):\n",
    "        if pd.isna(area):\n",
    "            return 'Kh√¥ng r√µ'\n",
    "        if area < 30:\n",
    "            return 'R·∫•t nh·ªè'\n",
    "        elif area < 50:\n",
    "            return 'Nh·ªè'\n",
    "        elif area < 80:\n",
    "            return 'Trung b√¨nh'\n",
    "        elif area < 150:\n",
    "            return 'L·ªõn'\n",
    "        else:\n",
    "            return 'R·∫•t l·ªõn'\n",
    "    \n",
    "    df['K√≠ch th∆∞·ªõc'] = df['Di·ªán t√≠ch (m2)'].apply(categorize_size)\n",
    "    print(\"  ‚úì Created 'K√≠ch th∆∞·ªõc' (size category)\")\n",
    "\n",
    "print(\"\\n‚úì Feature engineering completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize new features\n",
    "if 'K√≠ch th∆∞·ªõc' in df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    size_counts = df['K√≠ch th∆∞·ªõc'].value_counts()\n",
    "    plt.pie(size_counts, labels=size_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Distribution by Property Size', fontsize=14, fontweight='bold')\n",
    "    plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Encoding Categorical Features\n",
    "\n",
    "Chuy·ªÉn ƒë·ªïi c√°c bi·∫øn categorical th√†nh d·∫°ng s·ªë"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üè∑Ô∏è  Encoding categorical features...\")\n",
    "\n",
    "categorical_cols = [\n",
    "    'Th√†nh ph·ªë',\n",
    "    'Ph∆∞·ªùng/X√£',\n",
    "    'Lo·∫°i h√¨nh',\n",
    "    'Gi·∫•y t·ªù ph√°p l√Ω',\n",
    "    'H∆∞·ªõng',\n",
    "    'T√¨nh tr·∫°ng n·ªôi th·∫•t'\n",
    "]\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        # Handle NaN by treating as a separate category\n",
    "        df[col] = df[col].fillna('Kh√¥ng r√µ')\n",
    "        df[f'{col}_encoded'] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le\n",
    "        n_categories = len(le.classes_)\n",
    "        print(f\"  ‚úì Encoded {col} ({n_categories} categories)\")\n",
    "\n",
    "print(\"\\n‚úì All categorical features encoded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem mapping c·ªßa m·ªôt v√†i categorical features\n",
    "print(\"\\nExample: Lo·∫°i h√¨nh encoding\")\n",
    "if 'Lo·∫°i h√¨nh' in df.columns:\n",
    "    mapping_df = pd.DataFrame({\n",
    "        'Original': label_encoders['Lo·∫°i h√¨nh'].classes_,\n",
    "        'Encoded': range(len(label_encoders['Lo·∫°i h√¨nh'].classes_))\n",
    "    })\n",
    "    print(mapping_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Scaling Features (Optional)\n",
    "\n",
    "**L∆∞u √Ω:** B·∫°n c√≥ th·ªÉ b·ªè qua b∆∞·ªõc n√†y n·∫øu kh√¥ng c·∫ßn scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B·ªè comment ƒë·ªÉ ch·∫°y scaling\n",
    "# print(\"üìè Scaling features...\")\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# cols_to_scale = ['Di·ªán t√≠ch (m2)', 'Chi·ªÅu ngang (m)', 'Chi·ªÅu d√†i (m)', 'S·ªë ph√≤ng ng·ªß', 'S·ªë ph√≤ng v·ªá sinh', 'S·ªë t·∫ßng']\n",
    "\n",
    "# for col in cols_to_scale:\n",
    "#     if col in df.columns:\n",
    "#         df[f'{col}_scaled'] = scaler.fit_transform(df[[col]])\n",
    "#         print(f\"  ‚úì Scaled {col}\")\n",
    "\n",
    "# print(\"\\n‚úì Features scaled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìà Summary Statistics:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Numeric features\n",
    "print(\"\\nNumeric Features:\")\n",
    "numeric_cols_display = df.select_dtypes(include=[np.number]).columns\n",
    "df[numeric_cols_display].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features\n",
    "print(\"\\nCategorical Features (Top 5 values):\")\n",
    "categorical_cols_display = ['Th√†nh ph·ªë', 'Lo·∫°i h√¨nh', 'Gi·∫•y t·ªù ph√°p l√Ω', 'T√¨nh tr·∫°ng n·ªôi th·∫•t']\n",
    "\n",
    "for col in categorical_cols_display:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(df[col].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualization: Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Select key numeric columns\n",
    "key_cols = ['Gi√° b√°n (VND)', 'Di·ªán t√≠ch (m2)', 'Chi·ªÅu ngang (m)', 'Chi·ªÅu d√†i (m)', \n",
    "            'S·ªë ph√≤ng ng·ªß', 'S·ªë ph√≤ng v·ªá sinh', 'S·ªë t·∫ßng', 'Gi√°/m2', 'T·ªïng s·ªë ph√≤ng']\n",
    "key_cols = [col for col in key_cols if col in df.columns]\n",
    "\n",
    "corr_matrix = df[key_cols].corr()\n",
    "\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix of Key Features', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. L∆∞u D·ªØ Li·ªáu ƒê√£ X·ª≠ L√Ω"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L∆∞u d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω\n",
    "output_file = 'nhatot_crawl4ai_processed.csv'\n",
    "backup_file = 'nhatot_crawl4ai_original_backup.csv'\n",
    "\n",
    "print(\"üíæ Saving files...\")\n",
    "\n",
    "# Save processed data\n",
    "df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "print(f\"‚úì Processed data: {output_file}\")\n",
    "print(f\"  ‚Üí {len(df):,} rows and {len(df.columns)} columns\")\n",
    "\n",
    "# Save original data backup\n",
    "df_original.to_csv(backup_file, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\n‚úì Original data backup: {backup_file}\")\n",
    "print(f\"  ‚Üí {len(df_original):,} rows and {len(df_original.columns)} columns\")\n",
    "\n",
    "print(f\"\\nüìÅ Files saved:\")\n",
    "print(f\"  ‚Ä¢ Original file (unchanged): {file_path}\")\n",
    "print(f\"  ‚Ä¢ Processed file (new): {output_file}\")\n",
    "print(f\"  ‚Ä¢ Backup file (new): {backup_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Chu·∫©n B·ªã Cho Machine Learning (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for modeling\n",
    "print(\"üéØ Preparing data for modeling...\")\n",
    "\n",
    "# Select feature columns (encoded and numeric)\n",
    "feature_cols = []\n",
    "for col in df.columns:\n",
    "    if '_encoded' in col:\n",
    "        feature_cols.append(col)\n",
    "    elif col in ['Di·ªán t√≠ch (m2)', 'Chi·ªÅu ngang (m)', 'Chi·ªÅu d√†i (m)', \n",
    "                 'S·ªë ph√≤ng ng·ªß', 'S·ªë ph√≤ng v·ªá sinh', 'S·ªë t·∫ßng', 'T·ªïng s·ªë ph√≤ng']:\n",
    "        feature_cols.append(col)\n",
    "\n",
    "X = df[feature_cols].fillna(0)\n",
    "y = df['Gi√° b√°n (VND)']\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"‚úì Train set: {len(X_train):,} samples\")\n",
    "print(f\"‚úì Test set: {len(X_test):,} samples\")\n",
    "print(f\"‚úì Features: {len(feature_cols)}\")\n",
    "print(f\"\\nFeature columns: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. K·∫øt Lu·∫≠n\n",
    "\n",
    "### ‚úÖ ƒê√£ ho√†n th√†nh:\n",
    "1. Load v√† backup d·ªØ li·ªáu g·ªëc\n",
    "2. L√†m s·∫°ch d·ªØ li·ªáu (empty rows, duplicates)\n",
    "3. X·ª≠ l√Ω missing values\n",
    "4. Chuy·ªÉn ƒë·ªïi gi√° t·ª´ text sang s·ªë\n",
    "5. X·ª≠ l√Ω c√°c c·ªôt s·ªë\n",
    "6. Feature engineering (t·∫°o features m·ªõi)\n",
    "7. Encoding categorical features\n",
    "8. L∆∞u d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω\n",
    "\n",
    "### üìä K·∫øt qu·∫£:\n",
    "- **File g·ªëc**: Kh√¥ng b·ªã thay ƒë·ªïi ‚úì\n",
    "- **File processed**: S·∫µn s√†ng cho modeling ‚úì\n",
    "- **File backup**: ƒê√£ l∆∞u an to√†n ‚úì\n",
    "\n",
    "### üéì B∆∞·ªõc ti·∫øp theo:\n",
    "B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng `X_train`, `X_test`, `y_train`, `y_test` ƒë·ªÉ train c√°c models nh∆∞:\n",
    "- Linear Regression\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- Neural Networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
